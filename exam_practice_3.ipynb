{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Exam : "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**submitted by Sreekanth Potlabathini(220088993)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all ther required libraries for building a model and validation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc,precision_score,recall_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataframe for final exam\n",
    "df = pd.read_csv(r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct exploratory analysis on the provided dataset. State your hypothesis based on the insights from your exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Id', 'var1'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['var2', 'var3', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all').transpose()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the above : all have medium hence they are all integers but need to check if the continuous or catagorical<br>\n",
    "'age' mean and mediun and almost in the same place.<br>\n",
    "'ana'- is binary<br>\n",
    " 'c_pho' - max value is too high<br>\n",
    " 'diab' - is binary<br>\n",
    " 'e_fract' - mean and median are close together<br>\n",
    " 'hbp' - is binary<br>\n",
    " 'plat' - need to analyse more<br>\n",
    " 's_c' - mean and median are normally distributed<br>\n",
    " 's_s' - mean and median are normally distributed<br>\n",
    " 'sex' - is binary male / female<br>\n",
    " 'smok' - is binary yes/no<br>\n",
    " 'time' - time of death<br>\n",
    " 'DEATH' - our target variable is binary which is good<br>\n",
    "<br>\n",
    "can you see outliers ? what do you understand from 50% and mean.<br>\n",
    "list variables which are catagorical.<br>\n",
    "<br>\n",
    "which variables are continuous.<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can you see outliers ? what do you understand from 50% and mean.\n",
    "list variables which are catagorical.\n",
    "\n",
    "which variables are continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing values:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the total data is around 1050 in Sate date but every other value is missing few details."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total count of null are less than 10% hence droping the Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['var'] = df['var'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "df.fillna(method='ffill', inplace=True) dependednt continuous variable\n",
    "df.interpolate(method='linear', inplace=True) linear relation only going\n",
    "df['column_name'].fillna('custom_value', inplace=True)\n",
    "df['column_name'] = df.groupby('group_column')['column_name'].transform(lambda x: x.fillna(x.median()))\n",
    "# avarange , mediam based on catigory. Assignment 3. \n",
    "# should not have drastic difference in values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True) * need to check for null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for modelling (i.e., data cleaning and feature engineering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "making dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = pd.get_dummies(df['Sex'],dtype=int)\n",
    "pd.concat([df,sex],axis=1)\n",
    "df.drop(['Sex'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['target'].map({'Abnormal':1, 'Normal':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate analysis - first we check the output variable and make sure it's balanced\n",
    "df.groupby('target').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio is\n",
    "60*100 / (122+60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thats decently balanced dataset. so planning to skip smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.astype('int')\n",
    "X_balance,Y_balance = SMOTE().fit_sample(X,Y)\n",
    "X_balance = pd.DataFrame(X_balance, columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue = 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['diab', 'DEATH']).size().unstack() / df.groupby('DEATH').size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['ana','DEATH']).size().unstack() / df.groupby('DEATH').size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ver little difference in values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change of data type using astype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['s_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['s_c']>8].index, axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['s_c']=np.log(df['s_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['s_c'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for continuous variables: plot the boxplots with the x-axis as the output variable, and y-axis as the continuous variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2, ax3),(ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 5))\n",
    "sns.boxplot(x='target', y='v1', data=df, order=df.groupby('target')['v1'].median().sort_values().index, ax=ax1)\n",
    "sns.boxplot(x='target', y='v1', data=df, order=df.groupby('target')['v1'].median().sort_values().index, ax=ax2)\n",
    "sns.boxplot(x='target', y='v1', data=df, order=df.groupby('target')['v1'].median().sort_values().index, ax=ax3)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'age',  'c_pho', 'e_fract' - show signs wiht different death<br>\n",
    "'ana','plat','s_c', 's_s', 'time' - show signs wiht different death <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above : are the variables meaning full for analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "catagorical variable : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['diab','DEATH']).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['diab', 'DEATH']).size().unstack() / df.groupby('DEATH').size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above : do they show difference in the output ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['Parch'])\n",
    "plt.show()\n",
    "sns.histplot(df['SibSp'])\n",
    "plt.show()\n",
    "sns.histplot(df['Fare'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['c_pho'] > 3000].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['var'] = np.log(df['var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check with PCA to drop features.\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "df_std = scaler.fit_transform(df)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "df_pca = pca.fit_transform(df_std)\n",
    "\n",
    "# The transformed data is an array, convert it back into a dataframe\n",
    "df_pca = pd.DataFrame(df_pca, columns=[f'PC{i+1}' for i in range(len(df.columns))])\n",
    "\n",
    "# Print the cumulative explained variance ratio\n",
    "cumsum_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "print('Cumulative explained variance ratio:', cumsum_variance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'00'number of varaibles explain the target value by 90%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = df.corr()\n",
    "dc['target'].sort_values(ascending=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "df=df[['target', 'sqft_living', 'grade', 'sqft_living15', 'bathrooms', 'view',\n",
    "       'bedrooms', 'lat', 'waterfront', 'floors', 'yr_renovated', 'renovated',\n",
    "       'yr_built', 'condition', 'long', 'year', 'quarter', 'month', 'age']]\n",
    "plt.figure(figsize=(30, 15))\n",
    "sns.heatmap(df.corr(),annot=True,cmap='viridis', square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.drop('DEATH',axis=1,inplace=True)\n",
    "dc.drop('DEATH',axis=0,inplace=True)\n",
    "dc.replace(1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_index, col_index = np.where(dc.values == dc.max().max())\n",
    "print(dc.index[row_index[0]])\n",
    "print(dc.columns[col_index[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.scatterplot(data=df,x ='time',y ='s_c',hue='DEATH')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns based on PCA count. \n",
    "df.drop('DEATH',axis=1,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some of the featueres are well corellared with each other and one of them can be selected to represent the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hd_cons'] = df['hd'].map({0:0, 1:1, 2:1, 3:1, 4:1})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "binning the continuous variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_Age(Age):\n",
    "    if Age > 60:\n",
    "        return \"High\"\n",
    "    elif 40 <= Age <= 60:\n",
    "        return \"Medium 1\"\n",
    "    elif 20 <= Age <= 40:\n",
    "        return \"Medium_2\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "df['Age_cat'] = df['Age'].apply(categorize_Age)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define new metrics (e.g., multiply columns together or create custom categories based on multiple variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['var'] = df['var1']+df['var2']\n",
    "df['var'].diff(1)\n",
    "df['var']=df['var']-1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " adding dummies for all catorical varianbles: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['AGE', 'YEARS_EMPLOYED', 'INCOME', 'INCOME_PER_MEMBER', 'INCOME_PER_CHILD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Age_cat'], prefix='Age',dtype=int)\n",
    "X_encoded = pd.get_dummies(X, columns=cat_columns, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df[num_columns],X_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier verification : "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end o f data preprocessing "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('target', axis=1)\n",
    "y=df['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "standardizaton & normalization :scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the train and test data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "# num_columns = ['AGE', 'YEARS_EMPLOYED', 'INCOME', 'INCOME_PER_MEMBER', 'INCOME_PER_CHILD']\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit_transform(df[])\n",
    "\n",
    "# norm = MinMaxScalar()\n",
    "# norm.fit_transform(df[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "both have 6 columns each so the shape is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "sns.scatterplot(x = x_train[:,0],y = x_train[:,1],hue=y_train,style = y_train)\n",
    "plt.show()\n",
    "# Slicing  - all rows, first two high correlated feature columns \n",
    "# for looking at y - spread. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the train data doesnt show any great clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modelling "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model to predict the output variable. Hint: you will need to try several models to find the best model for your problem.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression, Naive Bayes, KNN, SVM, Decision Tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection\n",
    "log = LogisticRegression()\n",
    "#\n",
    "nb = GaussianNB()\n",
    "#\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "#\n",
    "tree = DecisionTreeClassifier(random_state=123)\n",
    "#\n",
    "svc = SVC(kernel='linear', random_state=123,probability=True)\n",
    "#\n",
    "models = [log, nb, knn, tree, svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(x_train,y_train)\n",
    "nb.fit(x_train,y_train)\n",
    "knn.fit(x_train,y_train)\n",
    "tree.fit(x_train,y_train)\n",
    "svc.fit(x_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(log, x_train, y_train, cv=10)\n",
    "print(cv_scores)\n",
    "print(cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(nb, x_train, y_train, cv=10)\n",
    "print(cv_scores)\n",
    "print(cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(knn, x_train, y_train, cv=10)\n",
    "print(cv_scores)\n",
    "print(cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(tree,  x_train, y_train, cv=10)\n",
    "print(cv_scores)\n",
    "print(cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(svc, x_train, y_train, cv=10)\n",
    "print(cv_scores)\n",
    "print(cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_log = log.predict_proba(x_test)\n",
    "yhat_nb = nb.predict_proba(x_test)\n",
    "yhat_knn = knn.predict_proba(x_test)\n",
    "yhat_tree = tree.predict_proba(x_test)\n",
    "yhat_svc = svc.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = log.predict(x_test)\n",
    "y_pred_nb = nb.predict(x_test)\n",
    "y_pred_knn = knn.predict(x_test)\n",
    "y_pred_tree = tree.predict(x_test)\n",
    "y_pred_svc = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_log, tpr_log, thresholds_l = roc_curve(y_test, yhat_log[:,1])\n",
    "fpr_nb, tpr_nb, thresholds_nb = roc_curve(y_test, yhat_nb[:,1])\n",
    "fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, yhat_nb[:,1]) # * check again\n",
    "fpr_tree, tpr_tree, thresholds_tree = roc_curve(y_test, yhat_tree[:,1])\n",
    "fpr_svc, tpr_svc, thresholds_svc = roc_curve(y_test, yhat_svc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(index = ['accuracy','precision', 'recall'], columns =['logisticReg','NaiveBayes','KNN','Tree','svc']   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.loc['accuracy','logisticReg'] = accuracy_score(y_pred=y_pred_log,y_true=y_test)\n",
    "metrics.loc['precision','logisticReg'] = precision_score(y_pred=y_pred_log,y_true=y_test)\n",
    "metrics.loc['recall','logisticReg'] = recall_score(y_pred=y_pred_log,y_true=y_test)\n",
    "print(confusion_matrix(y_pred=y_pred_log,y_true=y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.loc['accuracy','NaiveBayes'] = accuracy_score(y_pred=y_pred_nb,y_true=y_test)\n",
    "metrics.loc['precision','NaiveBayes'] = precision_score(y_pred=y_pred_nb,y_true=y_test)\n",
    "metrics.loc['recall','NaiveBayes'] = recall_score(y_pred=y_pred_nb,y_true=y_test)\n",
    "print(confusion_matrix(y_pred=y_pred_nb,y_true=y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.loc['accuracy','KNN'] = accuracy_score(y_pred=y_pred_knn,y_true=y_test)\n",
    "metrics.loc['precision','KNN'] = precision_score(y_pred=y_pred_knn,y_true=y_test)\n",
    "metrics.loc['recall','KNN'] = recall_score(y_pred=y_pred_knn,y_true=y_test)\n",
    "print(confusion_matrix(y_pred=y_pred_knn,y_true=y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,y_pred_knn))\n",
    "# order of detail inputed is important. Since predictied and actual order can interchange the values of FP & FN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.loc['accuracy','Tree'] = accuracy_score(y_pred=y_pred_tree,y_true=y_test)\n",
    "metrics.loc['precision','Tree'] = precision_score(y_pred=y_pred_tree,y_true=y_test)\n",
    "metrics.loc['recall','Tree'] = recall_score(y_pred=y_pred_tree,y_true=y_test)\n",
    "print(confusion_matrix(y_pred=y_pred_tree,y_true=y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.loc['accuracy','svc'] = accuracy_score(y_pred=y_pred_svc,y_true=y_test)\n",
    "metrics.loc['precision','svc'] = precision_score(y_pred=y_pred_svc,y_true=y_test)\n",
    "metrics.loc['recall','svc'] = recall_score(y_pred=y_pred_svc,y_true=y_test)\n",
    "print(confusion_matrix(y_pred=y_pred_svc,y_true=y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,y_pred_svc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate each model using the evaluation techniques you have learned in class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting decision tree\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(20,20))\n",
    "feature_names = x_train.columns\n",
    "plot_tree(tree, filled=True, rounded=True, feature_names=feature_names, class_names=['0', '1']);\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some of the features have been adjusted based on decision tree outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 30))\n",
    "plt.plot(fpr_log,tpr_log, label='log')\n",
    "plt.plot(fpr_nb,tpr_nb, label='nb')\n",
    "plt.plot(fpr_knn,tpr_knn, label='knn')\n",
    "plt.plot(fpr_tree,tpr_tree, label='tree')\n",
    "plt.plot(fpr_svc,tpr_svc, label='svc')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc scores\n",
    "print('logistic_regression : ',auc(fpr_log,tpr_log))\n",
    "print('NaiveBayes : ',auc(fpr_nb,tpr_nb))\n",
    "print('KNN : ',auc(fpr_knn,tpr_knn))\n",
    "print('Tree : ',auc(fpr_tree,tpr_tree))\n",
    "print('Svc : ',auc(fpr_svc,tpr_svc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------- is best . Doing hyper parameter tuning based off it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.01, 0.1, 1, 10],'solver': ['lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "\n",
    "model = LogisticRegression()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=10, scoring='accuracy')\n",
    "randomsearch = RandomizedSearchCV(model, param_grid, cv=10, n_iter=100, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "randomsearch.fit(x_train, y_train)\n",
    "print(\"Best Hyperparameters grid:\", grid_search.best_params_)\n",
    "print(\"Best Hyperparameters Random:\", randomsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grids for each model\n",
    "log_reg_param_grid = {'C': [0.01, 0.1, 1, 10],'solver': ['lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "knn_param_grid = {'n_neighbors': list(range(1, 20)),'weights': ['uniform', 'distance'],'metric': ['l1', 'euclidean', 'manhattan', 'sokalsneath', 'hamming', 'sokalmichener', 'rogerstanimoto', 'braycurtis', 'dice', 'jaccard', 'pyfunc', 'haversine', 'matching', 'cityblock', 'correlation', 'l2', 'nan_euclidean', 'chebyshev', 'p', 'wminkowski', 'minkowski', 'cosine', 'infinity', 'russellrao', 'seuclidean', 'canberra', 'kulsinski', 'sqeuclidean', 'yule', 'mahalanobis']}\n",
    "decision_tree_param_grid = {'criterion': ['gini', 'entropy'],'max_depth': [None, 10, 20, 30],'min_samples_split': [2, 5, 10],'min_samples_leaf': [1, 2, 4]}\n",
    "svc_param_grid = {'C': [0.1, 1, 10],'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],'gamma': ['scale', 'auto'],'class_weight': [None, 'balanced']}\n",
    "\n",
    "# Create models\n",
    "log_reg_model = LogisticRegression()\n",
    "naive_bayes_model = GaussianNB()\n",
    "knn_model = KNeighborsClassifier()\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "svc_model = SVC()\n",
    "\n",
    "# Perform RandomizedSearchCV  for each model\n",
    "random_search_log_reg = RandomizedSearchCV(log_reg_model, log_reg_param_grid, cv=10, n_iter=100, scoring='accuracy')\n",
    "random_search_knn = RandomizedSearchCV(knn_model, knn_param_grid, cv=10, n_iter=100, scoring='accuracy')\n",
    "random_search_decision_tree = RandomizedSearchCV(decision_tree_model, decision_tree_param_grid, cv=10, n_iter=100, scoring='accuracy')\n",
    "random_search_svc = RandomizedSearchCV(svc_model, svc_param_grid, cv=10, n_iter=100, scoring='accuracy')\n",
    "\n",
    "\n",
    "# Perform GridSearchCV for each model\n",
    "grid_search_log_reg = GridSearchCV(log, log_reg_param_grid, cv=10, scoring='accuracy')\n",
    "grid_search_knn = GridSearchCV(knn_model, knn_param_grid, cv=10, scoring='accuracy')\n",
    "grid_search_decision_tree = GridSearchCV(decision_tree_model, decision_tree_param_grid, cv=10, scoring='accuracy')\n",
    "grid_search_svc = GridSearchCV(svc_model, svc_param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "\n",
    "# Fit the models and find best hyperparameters\n",
    "random_search_log_reg.fit(x_train, y_train)\n",
    "random_search_knn.fit(x_train, y_train)\n",
    "random_search_decision_tree.fit(x_train, y_train)\n",
    "random_search_svc.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best parameters from RandomSearch: \", randomsearch_knn.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from both considering random: <br>\n",
    "{'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 30, 'criterion': 'entropy'}<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying the best Hyperparameters:Modle optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = LogisticRegression(**randomsearch.best_params_)\n",
    "cv_scores = cross_val_score(best_model, x_train, y_train, cv=10, scoring='accuracy')\n",
    "best_model.fit(x_train, y_train)\n",
    "# Predict\n",
    "y_hat_best = best_model.predict_proba(x_test)\n",
    "y_pred_best = best_model.predict(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add some details of the output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Check performance metrics: precision, recall, F1 score, roc_auc, accuracy score \n",
    "* If your model isn't performing well, try adding/removing variables, or engineering more features \n",
    "* Once you're confident you have tried everything possible to build the best possible model, you can finalize your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_pred=y_pred_best, y_true=y_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Explaining your results \n",
    "* Explain your results by always connecting your decisions to the business problem provided. \n",
    "* Explain your process > how did you decide to clean the data? how do you know that was the best decision? what did you learn from exploratory analysis, and how did this inform your modelling decisions? Which features did you engineer? how did you pick these?  \n",
    "* Explain the final model > which variables were included in the model, and what was the model performance? \n",
    "* Explain how this model can be applied to the future to predict outcomes > how will the business use the model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, best_model.predict_proba(x_test)[:, 1])\n",
    "plt.plot(fpr, tpr, label=best_model.__class__.__name__)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Explain your model to a business executive. Your explanation should include the following:\n",
    "\n",
    "i. Your data exploration findings, initial hypothesis, and whether the hypothesis proved true.\n",
    "\n",
    "ii. Your approach for building and evaluating the model. \n",
    "\n",
    "iii. The final model you selected and how you know this is the best model for the problem.\n",
    "\n",
    "iv. How the model should be used by the business, in business process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "did you refer notes ? \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fir , trankssform, fit transform.\n",
    "closing a model prediction. how to finsih the mdoel.\n",
    "model deplyment.\n",
    "confirmatory data analysis ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
